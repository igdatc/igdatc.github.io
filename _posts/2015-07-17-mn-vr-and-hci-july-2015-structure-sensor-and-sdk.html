---
layout: post
title: 'MN VR and HCI July 2015: Structure Sensor and SDK'
date: 2015-07-17 12:05:54.000000000 -05:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
- Events
- Meetings
- MN VR and HCI
tags: []
meta:
  _edit_last: '7'
  _oembed_28dee6f632b605852a9a384a23a06470: "{{unknown}}"
  _oembed_0a90d895cc1564dff8d5e1bf57431887: "{{unknown}}"
  _wpas_done_all: '1'
author:
  login: Martin
  email: mgrider@gmail.com
  display_name: Martin
  first_name: Martin
  last_name: Grider
permalink: "/2015/07/mn-vr-and-hci-july-2015-structure-sensor-and-sdk/"
---
<p><strong> Structure Sensor and SDK - Jim Selikoff, Developer Evangelist for <a href="http://occipital.com/">Occipital</a></strong><br />
Wednesday, July 29, 2015 from 6:30 PM to 9:00 PM (CDT)<br />
Vidku - 251 N 1st Ave. Minneapolis, MN 55401</p>
<p><a href="http://www.eventbrite.com/e/mn-vr-and-hci-july-2015-structure-sensor-and-sdk-tickets-17800921034">Register on Eventbrite!</a></p>
<p><strong> NOTE: Moved to the 29th, new host, and pizza.  Thanks <a href="http://vidku.com">Vidku</a>!</strong></p>
<p>Structure shipped in 2014 as the first 3D sensor for mobile hardware, with 3 core capabilities:</p>
<ul>
<li>Reliable 3D scanning with high-res textures</li>
<li>Quick room mapping and measuring</li>
<li>Multi-modal 6DOF positional tracking (for VR/AR)</li>
</ul>
<p>Structure was quickly adopted for a variety of 3d scanning applications. As developer experience and the SDK has matured, the capabilities are being combined for interesting use cases like:</p>
<ul>
<li>Pre-vis at ILM and on Agents of Shield</li>
<li>Medical wound care</li>
<li>Capturing realistic face blenshapes and textures</li>
<li>Bringing your real environment into a VR or AR scene in real-time</li>
</ul>
<p><img src="{{ site.baseurl }}/assets/635696295470357318-ILMxLAB-bg.2.jpeg" width="540" height="380" class="alignnone" /></p>
<p><img src="{{ site.baseurl }}/assets/maxresdefault.jpg" width="1280" height="720" class="alignnone" /></p>
<p>The Structure SDK for iOS provides both a low level sensor control layer for raw depth and color streaming, as well as a high level SLAM (Simultaneous Localization and Mapping) layer that includes 3D mapping, tracking and scanning features. For non-iOS platforms, Occipital have taken over the maintenance and evolution of the OSS project OpenNI which enables low level depth streaming on Windows, Android, and Linux platforms.</p>
<p>Come learn how to leverage this incredible technology as we demonstrate and discuss the sensor capabilities along with the design and use of the SDK.<br />
You might even be digitized for safe keeping!</p>
<p><strong>Parking:</strong><br />
There is nearby street parking and lots of nearby surface lots.  Locals say check the lots at 1st and Washington (both sides of Pixel Farm), and 3rd and Hennepin (behind Vidku.)  Bring cash.</p>
<p><strong>Schedule:</strong></p>
<div>
<p>6:15 Social and setup<br />
6:45 MARS Lab<br />
8:00 Wrap up, head to BWW</p>
<p>After, We'll head to Buffalo Wild Wings on University Ave, by the stadium.<a href="https://goo.gl/maps/zmbWm" rel="nofollow"> https://goo.gl/maps/zmbWm</a></p>
</div>
<div>
<div></div>
<div></div>
<div><strong>About MN VR and HCI:</strong></div>
<div></div>
<div>MN VR and HCI (Human-Computer Interaction) welcomes developers and tinkerers working with all variety of VR,  HCI, hardware hacking, creative coding and interactive art   Members are working projects with light field displays, mocap, tiny computers, servos and sensors, interactive statues and a variety of VR, motion and computer vision games.</div>
<div></div>
<div>If you've only been to our parent group IGDATC meetings, MN VR and HCI is a different format: We aim for smaller group discussions and lots of specific details.</div>
</div>
